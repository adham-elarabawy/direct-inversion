{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Inversion: Optimization-Free Text-Driven Real Image Editing with Diffusion Models\n",
    "@author: Adham Elarabawy // aelarabawy@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import PIL\n",
    "import numpy as np\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import PNDMScheduler, DDIMScheduler, LMSDiscreteScheduler\n",
    "from pipeline.direct_inversion_pipeline import DirectInversionPipeline\n",
    "from tqdm import tqdm\n",
    "from pipeline.util import image_grid, encode, decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\"\n",
    "remove_safety = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Direct Inversion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = DirectInversionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16, revision=\"fp16\", use_auth_token=True)\n",
    "\n",
    "if remove_safety:\n",
    "  pipe.safety_checker = lambda images, clip_input: (images, False)\n",
    "  \n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Direct Inversion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill this out:\n",
    "in_img = Image.open(\"images/shoes.png\").convert(\"RGB\").resize((512,512))\n",
    "prompt = \"black dress shoes\" \n",
    "inversion_prompt = \"\"\n",
    "num_images = 1\n",
    "guidance_scale = 3          # in range [0, 10]\n",
    "noise_merge_lambda = 0.5    # in range [0, 1]\n",
    "num_inference_steps = 100   # in range [0, 1000] *Recommend keeping at 100*\n",
    "num_inversion_steps = 100   # in range [0, 1000] *Recommend keeping at 100*\n",
    "direct_injection = True     # toggle if we start from random noise [False] or if we start from inverted noise [True]\n",
    "stochastic_injection = True # toggle if we continually inject inverted noise\n",
    "num_stochastic_injection_steps = num_inference_steps # how many steps we inject inverted noise for\n",
    "stochastic_injection_exp_method = True # toggle if we want to use the scaled noises predicted during inversion for stochastic injection\n",
    "\n",
    "log = []\n",
    "output = []\n",
    "prompts = [ prompt ] * num_images\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompts, \n",
    "                guidance_scale=guidance_scale, \n",
    "                num_inference_steps=num_inference_steps, \n",
    "                input_image=in_img, \n",
    "                direct_injection=direct_injection,\n",
    "                stochastic_injection=stochastic_injection, \n",
    "                inversion_steps=num_inversion_steps,\n",
    "                noise_merge_lambda=noise_merge_lambda,\n",
    "                num_stochastic_injection_steps=num_stochastic_injection_steps,\n",
    "                inversion_prompt=inversion_prompt,\n",
    "                debug_print=True,\n",
    "                stochastic_injection_exp_method=stochastic_injection_exp_method)\n",
    "    images = out[0][\"sample\"]\n",
    "    # DEBUG [Not enabled for release]\n",
    "    # noises = out[1]\n",
    "    # cleans = out[2]\n",
    "    images.insert(0, in_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid(images, 1, len(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
